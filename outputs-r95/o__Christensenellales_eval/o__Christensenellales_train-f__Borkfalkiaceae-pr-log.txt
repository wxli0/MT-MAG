alpha = 0.0 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.01 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.02 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.03 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.04 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.05 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.06 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.07 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.08 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.09 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.1 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.11 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.12 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.13 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.14 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.15 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.16 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.17 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.18 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.19 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.2 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.21 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.22 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.23 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.24 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.25 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.26 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.27 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.28 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.29 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.3 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.31 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.32 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.33 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.34 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.35000000000000003 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.36 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.37 precision: 0.8205128205128205 recall: 0.8205128205128205 weighted: 0.8205128205128205
alpha = 0.38 precision: 0.8108108108108109 recall: 0.7692307692307693 weighted: 0.7900207900207901
alpha = 0.39 precision: 0.8108108108108109 recall: 0.7692307692307693 weighted: 0.7900207900207901
alpha = 0.4 precision: 0.8108108108108109 recall: 0.7692307692307693 weighted: 0.7900207900207901
alpha = 0.41000000000000003 precision: 0.8108108108108109 recall: 0.7692307692307693 weighted: 0.7900207900207901
alpha = 0.42 precision: 0.8285714285714286 recall: 0.7435897435897436 weighted: 0.7860805860805862
alpha = 0.43 precision: 0.8285714285714286 recall: 0.7435897435897436 weighted: 0.7860805860805862
alpha = 0.44 precision: 0.8285714285714286 recall: 0.7435897435897436 weighted: 0.7860805860805862
alpha = 0.45 precision: 0.8285714285714286 recall: 0.7435897435897436 weighted: 0.7860805860805862
alpha = 0.46 precision: 0.8285714285714286 recall: 0.7435897435897436 weighted: 0.7860805860805862
alpha = 0.47000000000000003 precision: 0.8285714285714286 recall: 0.7435897435897436 weighted: 0.7860805860805862
alpha = 0.48 precision: 0.8285714285714286 recall: 0.7435897435897436 weighted: 0.7860805860805862
alpha = 0.49 precision: 0.8285714285714286 recall: 0.7435897435897436 weighted: 0.7860805860805862
alpha = 0.5 precision: 0.8787878787878788 recall: 0.7435897435897436 weighted: 0.8111888111888113
alpha = 0.51 precision: 0.8787878787878788 recall: 0.7435897435897436 weighted: 0.8111888111888113
alpha = 0.52 precision: 0.8787878787878788 recall: 0.7435897435897436 weighted: 0.8111888111888113
alpha = 0.53 precision: 0.8787878787878788 recall: 0.7435897435897436 weighted: 0.8111888111888113
alpha = 0.54 precision: 0.9354838709677419 recall: 0.7435897435897436 weighted: 0.8395368072787428
alpha = 0.55 precision: 0.9354838709677419 recall: 0.7435897435897436 weighted: 0.8395368072787428
alpha = 0.56 precision: 0.9333333333333333 recall: 0.717948717948718 weighted: 0.8256410256410256
alpha = 0.5700000000000001 precision: 0.9310344827586207 recall: 0.6923076923076923 weighted: 0.8116710875331565
alpha = 0.58 precision: 0.9310344827586207 recall: 0.6923076923076923 weighted: 0.8116710875331565
alpha = 0.59 precision: 0.9259259259259259 recall: 0.6410256410256411 weighted: 0.7834757834757835
alpha = 0.6 precision: 0.9230769230769231 recall: 0.6153846153846154 weighted: 0.7692307692307693
alpha = 0.61 precision: 0.9230769230769231 recall: 0.6153846153846154 weighted: 0.7692307692307693
alpha = 0.62 precision: 0.9230769230769231 recall: 0.6153846153846154 weighted: 0.7692307692307693
alpha = 0.63 precision: 0.9230769230769231 recall: 0.6153846153846154 weighted: 0.7692307692307693
alpha = 0.64 precision: 0.9230769230769231 recall: 0.6153846153846154 weighted: 0.7692307692307693
alpha = 0.65 precision: 0.9230769230769231 recall: 0.6153846153846154 weighted: 0.7692307692307693
alpha = 0.66 precision: 0.92 recall: 0.5897435897435898 weighted: 0.7548717948717949
alpha = 0.67 precision: 0.92 recall: 0.5897435897435898 weighted: 0.7548717948717949
alpha = 0.68 precision: 0.92 recall: 0.5897435897435898 weighted: 0.7548717948717949
alpha = 0.6900000000000001 precision: 0.92 recall: 0.5897435897435898 weighted: 0.7548717948717949
alpha = 0.7000000000000001 precision: 0.9130434782608695 recall: 0.5384615384615384 weighted: 0.725752508361204
alpha = 0.71 precision: 0.9130434782608695 recall: 0.5384615384615384 weighted: 0.725752508361204
alpha = 0.72 precision: 0.9130434782608695 recall: 0.5384615384615384 weighted: 0.725752508361204
alpha = 0.73 precision: 0.9130434782608695 recall: 0.5384615384615384 weighted: 0.725752508361204
alpha = 0.74 precision: 0.9130434782608695 recall: 0.5384615384615384 weighted: 0.725752508361204
alpha = 0.75 precision: 0.9130434782608695 recall: 0.5384615384615384 weighted: 0.725752508361204
alpha = 0.76 precision: 0.9047619047619048 recall: 0.48717948717948717 weighted: 0.6959706959706959
alpha = 0.77 precision: 0.9047619047619048 recall: 0.48717948717948717 weighted: 0.6959706959706959
alpha = 0.78 precision: 1.0 recall: 0.48717948717948717 weighted: 0.7435897435897436
alpha = 0.79 precision: 1.0 recall: 0.4358974358974359 weighted: 0.717948717948718
alpha = 0.8 precision: 1.0 recall: 0.41025641025641024 weighted: 0.7051282051282051
alpha = 0.81 precision: 1.0 recall: 0.41025641025641024 weighted: 0.7051282051282051
alpha = 0.8200000000000001 precision: 1.0 recall: 0.41025641025641024 weighted: 0.7051282051282051
alpha = 0.8300000000000001 precision: 1.0 recall: 0.41025641025641024 weighted: 0.7051282051282051
alpha = 0.84 precision: 1.0 recall: 0.358974358974359 weighted: 0.6794871794871795
alpha = 0.85 precision: 1.0 recall: 0.3333333333333333 weighted: 0.6666666666666666
alpha = 0.86 precision: 1.0 recall: 0.3076923076923077 weighted: 0.6538461538461539
alpha = 0.87 precision: 1.0 recall: 0.28205128205128205 weighted: 0.641025641025641
alpha = 0.88 precision: 1.0 recall: 0.2564102564102564 weighted: 0.6282051282051282
alpha = 0.89 precision: 1.0 recall: 0.2564102564102564 weighted: 0.6282051282051282
alpha = 0.9 precision: 1.0 recall: 0.2564102564102564 weighted: 0.6282051282051282
alpha = 0.91 precision: 1.0 recall: 0.20512820512820512 weighted: 0.6025641025641025
alpha = 0.92 precision: 1.0 recall: 0.1794871794871795 weighted: 0.5897435897435898
alpha = 0.93 precision: 1.0 recall: 0.1794871794871795 weighted: 0.5897435897435898
alpha = 0.9400000000000001 precision: 1.0 recall: 0.15384615384615385 weighted: 0.5769230769230769
alpha = 0.9500000000000001 precision: 1.0 recall: 0.07692307692307693 weighted: 0.5384615384615384
alpha = 0.96 precision: 1.0 recall: 0.02564102564102564 weighted: 0.5128205128205128
alpha = 0.97 precision: 1.0 recall: 0.02564102564102564 weighted: 0.5128205128205128
alpha = 0.98 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.99 precision: 1 recall: 0.0 weighted: 0.5
alpha = 1.0 precision: 1 recall: 0.0 weighted: 0.5
file name is: outputs/o__Christensenellales_train.xlsx
split results is: ['outputs', 'o__Christensenellales_train.xlsx']
