alpha = 0.0 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.01 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.02 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.03 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.04 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.05 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.06 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.07 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.08 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.09 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.1 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.11 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.12 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.13 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.14 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.15 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.16 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.17 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.18 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.19 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.2 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.21 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.22 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.23 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.24 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.25 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.26 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.27 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.28 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.29 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.3 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.31 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.32 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.33 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.34 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.35000000000000003 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.36 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.37 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.38 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.39 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.4 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.41000000000000003 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.42 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.43 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.44 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.45 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.46 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.47000000000000003 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.48 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.49 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.5 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.51 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.52 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.53 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.54 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.55 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.56 precision: 0.8055555555555556 recall: 0.8055555555555556 weighted: 0.8055555555555556
alpha = 0.5700000000000001 precision: 0.8 recall: 0.7777777777777778 weighted: 0.788888888888889
alpha = 0.58 precision: 0.8 recall: 0.7777777777777778 weighted: 0.788888888888889
alpha = 0.59 precision: 0.8235294117647058 recall: 0.7777777777777778 weighted: 0.8006535947712419
alpha = 0.6 precision: 0.8235294117647058 recall: 0.7777777777777778 weighted: 0.8006535947712419
alpha = 0.61 precision: 0.8235294117647058 recall: 0.7777777777777778 weighted: 0.8006535947712419
alpha = 0.62 precision: 0.8235294117647058 recall: 0.7777777777777778 weighted: 0.8006535947712419
alpha = 0.63 precision: 0.8235294117647058 recall: 0.7777777777777778 weighted: 0.8006535947712419
alpha = 0.64 precision: 0.8181818181818182 recall: 0.75 weighted: 0.7840909090909092
alpha = 0.65 precision: 0.8181818181818182 recall: 0.75 weighted: 0.7840909090909092
alpha = 0.66 precision: 0.8181818181818182 recall: 0.75 weighted: 0.7840909090909092
alpha = 0.67 precision: 0.8181818181818182 recall: 0.75 weighted: 0.7840909090909092
alpha = 0.68 precision: 0.8181818181818182 recall: 0.75 weighted: 0.7840909090909092
alpha = 0.6900000000000001 precision: 0.8181818181818182 recall: 0.75 weighted: 0.7840909090909092
alpha = 0.7000000000000001 precision: 0.8709677419354839 recall: 0.75 weighted: 0.810483870967742
alpha = 0.71 precision: 0.8709677419354839 recall: 0.75 weighted: 0.810483870967742
alpha = 0.72 precision: 0.8709677419354839 recall: 0.75 weighted: 0.810483870967742
alpha = 0.73 precision: 0.8709677419354839 recall: 0.75 weighted: 0.810483870967742
alpha = 0.74 precision: 0.8709677419354839 recall: 0.75 weighted: 0.810483870967742
alpha = 0.75 precision: 0.8709677419354839 recall: 0.75 weighted: 0.810483870967742
alpha = 0.76 precision: 0.8709677419354839 recall: 0.75 weighted: 0.810483870967742
alpha = 0.77 precision: 0.9 recall: 0.75 weighted: 0.825
alpha = 0.78 precision: 0.9 recall: 0.75 weighted: 0.825
alpha = 0.79 precision: 0.896551724137931 recall: 0.7222222222222222 weighted: 0.8093869731800767
alpha = 0.8 precision: 0.9285714285714286 recall: 0.7222222222222222 weighted: 0.8253968253968254
alpha = 0.81 precision: 0.9285714285714286 recall: 0.7222222222222222 weighted: 0.8253968253968254
alpha = 0.8200000000000001 precision: 0.9285714285714286 recall: 0.7222222222222222 weighted: 0.8253968253968254
alpha = 0.8300000000000001 precision: 0.92 recall: 0.6388888888888888 weighted: 0.7794444444444444
alpha = 0.84 precision: 0.9166666666666666 recall: 0.6111111111111112 weighted: 0.7638888888888888
alpha = 0.85 precision: 0.9090909090909091 recall: 0.5555555555555556 weighted: 0.7323232323232323
alpha = 0.86 precision: 0.9047619047619048 recall: 0.5277777777777778 weighted: 0.7162698412698413
alpha = 0.87 precision: 0.9 recall: 0.5 weighted: 0.7
alpha = 0.88 precision: 0.9 recall: 0.5 weighted: 0.7
alpha = 0.89 precision: 0.9 recall: 0.5 weighted: 0.7
alpha = 0.9 precision: 0.8947368421052632 recall: 0.4722222222222222 weighted: 0.6834795321637427
alpha = 0.91 precision: 0.875 recall: 0.3888888888888889 weighted: 0.6319444444444444
alpha = 0.92 precision: 0.8333333333333334 recall: 0.2777777777777778 weighted: 0.5555555555555556
alpha = 0.93 precision: 0.8888888888888888 recall: 0.2222222222222222 weighted: 0.5555555555555556
alpha = 0.9400000000000001 precision: 0.8888888888888888 recall: 0.2222222222222222 weighted: 0.5555555555555556
alpha = 0.9500000000000001 precision: 0.8888888888888888 recall: 0.2222222222222222 weighted: 0.5555555555555556
alpha = 0.96 precision: 0.8333333333333334 recall: 0.1388888888888889 weighted: 0.48611111111111116
alpha = 0.97 precision: 1.0 recall: 0.05555555555555555 weighted: 0.5277777777777778
alpha = 0.98 precision: 1.0 recall: 0.027777777777777776 weighted: 0.5138888888888888
alpha = 0.99 precision: 1 recall: 0.0 weighted: 0.5
alpha = 1.0 precision: 1 recall: 0.0 weighted: 0.5
file name is: outputs/c__Bacilli_train.xlsx
split results is: ['outputs', 'c__Bacilli_train.xlsx']
