alpha = 0.0 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.01 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.02 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.03 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.04 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.05 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.06 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.07 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.08 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.09 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.1 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.11 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.12 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.13 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.14 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.15 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.16 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.17 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.18 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.19 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.2 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.21 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.22 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.23 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.24 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.25 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.26 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.27 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.28 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.29 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.3 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.31 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.32 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.33 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.34 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.35000000000000003 precision: 0.9661016949152542 recall: 0.9661016949152542 weighted: 0.9661016949152542
alpha = 0.36 precision: 0.9658119658119658 recall: 0.9576271186440678 weighted: 0.9617195422280168
alpha = 0.37 precision: 0.9658119658119658 recall: 0.9576271186440678 weighted: 0.9617195422280168
alpha = 0.38 precision: 0.9658119658119658 recall: 0.9576271186440678 weighted: 0.9617195422280168
alpha = 0.39 precision: 0.9658119658119658 recall: 0.9576271186440678 weighted: 0.9617195422280168
alpha = 0.4 precision: 0.9658119658119658 recall: 0.9576271186440678 weighted: 0.9617195422280168
alpha = 0.41000000000000003 precision: 0.9658119658119658 recall: 0.9576271186440678 weighted: 0.9617195422280168
alpha = 0.42 precision: 0.9658119658119658 recall: 0.9576271186440678 weighted: 0.9617195422280168
alpha = 0.43 precision: 0.9655172413793104 recall: 0.9491525423728814 weighted: 0.9573348918760959
alpha = 0.44 precision: 0.9655172413793104 recall: 0.9491525423728814 weighted: 0.9573348918760959
alpha = 0.45 precision: 0.9649122807017544 recall: 0.9322033898305084 weighted: 0.9485578352661315
alpha = 0.46 precision: 0.9649122807017544 recall: 0.9322033898305084 weighted: 0.9485578352661315
alpha = 0.47000000000000003 precision: 0.9649122807017544 recall: 0.9322033898305084 weighted: 0.9485578352661315
alpha = 0.48 precision: 0.9649122807017544 recall: 0.9322033898305084 weighted: 0.9485578352661315
alpha = 0.49 precision: 0.9649122807017544 recall: 0.9322033898305084 weighted: 0.9485578352661315
alpha = 0.5 precision: 0.9646017699115044 recall: 0.923728813559322 weighted: 0.9441652917354132
alpha = 0.51 precision: 0.9642857142857143 recall: 0.9152542372881356 weighted: 0.9397699757869249
alpha = 0.52 precision: 0.963963963963964 recall: 0.9067796610169492 weighted: 0.9353718124904566
alpha = 0.53 precision: 0.9636363636363636 recall: 0.8983050847457628 weighted: 0.9309707241910632
alpha = 0.54 precision: 0.9636363636363636 recall: 0.8983050847457628 weighted: 0.9309707241910632
alpha = 0.55 precision: 0.9636363636363636 recall: 0.8983050847457628 weighted: 0.9309707241910632
alpha = 0.56 precision: 0.9636363636363636 recall: 0.8983050847457628 weighted: 0.9309707241910632
alpha = 0.5700000000000001 precision: 0.9636363636363636 recall: 0.8983050847457628 weighted: 0.9309707241910632
alpha = 0.58 precision: 0.9636363636363636 recall: 0.8983050847457628 weighted: 0.9309707241910632
alpha = 0.59 precision: 0.963302752293578 recall: 0.8898305084745762 weighted: 0.9265666303840772
alpha = 0.6 precision: 0.963302752293578 recall: 0.8898305084745762 weighted: 0.9265666303840772
alpha = 0.61 precision: 0.9626168224299065 recall: 0.8728813559322034 weighted: 0.9177490891810549
alpha = 0.62 precision: 0.9626168224299065 recall: 0.8728813559322034 weighted: 0.9177490891810549
alpha = 0.63 precision: 0.9622641509433962 recall: 0.864406779661017 weighted: 0.9133354653022066
alpha = 0.64 precision: 0.9622641509433962 recall: 0.864406779661017 weighted: 0.9133354653022066
alpha = 0.65 precision: 0.9705882352941176 recall: 0.8389830508474576 weighted: 0.9047856430707877
alpha = 0.66 precision: 0.9705882352941176 recall: 0.8389830508474576 weighted: 0.9047856430707877
alpha = 0.67 precision: 0.98 recall: 0.8305084745762712 weighted: 0.9052542372881356
alpha = 0.68 precision: 0.9791666666666666 recall: 0.7966101694915254 weighted: 0.887888418079096
alpha = 0.6900000000000001 precision: 0.9764705882352941 recall: 0.7033898305084746 weighted: 0.8399302093718843
alpha = 0.7000000000000001 precision: 0.975 recall: 0.6610169491525424 weighted: 0.8180084745762712
alpha = 0.71 precision: 0.9736842105263158 recall: 0.6271186440677966 weighted: 0.8004014272970562
alpha = 0.72 precision: 0.9736842105263158 recall: 0.6271186440677966 weighted: 0.8004014272970562
alpha = 0.73 precision: 1.0 recall: 0.6101694915254238 weighted: 0.8050847457627119
alpha = 0.74 precision: 1.0 recall: 0.5508474576271186 weighted: 0.7754237288135593
alpha = 0.75 precision: 1.0 recall: 0.5084745762711864 weighted: 0.7542372881355932
alpha = 0.76 precision: 1.0 recall: 0.4661016949152542 weighted: 0.7330508474576272
alpha = 0.77 precision: 1.0 recall: 0.4661016949152542 weighted: 0.7330508474576272
alpha = 0.78 precision: 1.0 recall: 0.4576271186440678 weighted: 0.728813559322034
alpha = 0.79 precision: 1.0 recall: 0.4491525423728814 weighted: 0.7245762711864407
alpha = 0.8 precision: 1.0 recall: 0.4491525423728814 weighted: 0.7245762711864407
alpha = 0.81 precision: 1.0 recall: 0.4491525423728814 weighted: 0.7245762711864407
alpha = 0.8200000000000001 precision: 1.0 recall: 0.423728813559322 weighted: 0.711864406779661
alpha = 0.8300000000000001 precision: 1.0 recall: 0.3813559322033898 weighted: 0.6906779661016949
alpha = 0.84 precision: 1.0 recall: 0.2966101694915254 weighted: 0.6483050847457628
alpha = 0.85 precision: 1.0 recall: 0.22033898305084745 weighted: 0.6101694915254238
alpha = 0.86 precision: 1.0 recall: 0.1440677966101695 weighted: 0.5720338983050848
alpha = 0.87 precision: 1.0 recall: 0.11864406779661017 weighted: 0.559322033898305
alpha = 0.88 precision: 1.0 recall: 0.11864406779661017 weighted: 0.559322033898305
alpha = 0.89 precision: 1.0 recall: 0.11016949152542373 weighted: 0.5550847457627118
alpha = 0.9 precision: 1.0 recall: 0.1016949152542373 weighted: 0.5508474576271186
alpha = 0.91 precision: 1.0 recall: 0.1016949152542373 weighted: 0.5508474576271186
alpha = 0.92 precision: 1.0 recall: 0.06779661016949153 weighted: 0.5338983050847458
alpha = 0.93 precision: 1.0 recall: 0.06779661016949153 weighted: 0.5338983050847458
alpha = 0.9400000000000001 precision: 1.0 recall: 0.06779661016949153 weighted: 0.5338983050847458
alpha = 0.9500000000000001 precision: 1.0 recall: 0.0423728813559322 weighted: 0.521186440677966
alpha = 0.96 precision: 1.0 recall: 0.03389830508474576 weighted: 0.5169491525423728
alpha = 0.97 precision: 1.0 recall: 0.01694915254237288 weighted: 0.5084745762711864
alpha = 0.98 precision: 1.0 recall: 0.00847457627118644 weighted: 0.5042372881355932
alpha = 0.99 precision: 1 recall: 0.0 weighted: 0.5
alpha = 1.0 precision: 1 recall: 0.0 weighted: 0.5
file name is: outputs/o__RF39_train.xlsx
split results is: ['outputs', 'o__RF39_train.xlsx']
