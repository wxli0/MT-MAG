alpha = 0.0 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.01 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.02 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.03 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.04 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.05 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.06 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.07 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.08 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.09 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.1 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.11 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.12 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.13 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.14 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.15 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.16 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.17 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.18 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.19 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.2 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.21 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.22 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.23 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.24 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.25 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.26 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.27 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.28 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.29 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.3 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.31 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.32 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.33 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.34 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.35000000000000003 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.36 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.37 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.38 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.39 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.4 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.41000000000000003 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.42 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.43 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.44 precision: 0.9557522123893806 recall: 0.9557522123893806 weighted: 0.9557522123893806
alpha = 0.45 precision: 0.9553571428571429 recall: 0.9469026548672567 weighted: 0.9511298988621998
alpha = 0.46 precision: 0.9553571428571429 recall: 0.9469026548672567 weighted: 0.9511298988621998
alpha = 0.47000000000000003 precision: 0.9553571428571429 recall: 0.9469026548672567 weighted: 0.9511298988621998
alpha = 0.48 precision: 0.9553571428571429 recall: 0.9469026548672567 weighted: 0.9511298988621998
alpha = 0.49 precision: 0.9553571428571429 recall: 0.9469026548672567 weighted: 0.9511298988621998
alpha = 0.5 precision: 0.9545454545454546 recall: 0.9292035398230089 weighted: 0.9418744971842317
alpha = 0.51 precision: 0.9541284403669725 recall: 0.9203539823008849 weighted: 0.9372412113339288
alpha = 0.52 precision: 0.9537037037037037 recall: 0.911504424778761 weighted: 0.9326040642412323
alpha = 0.53 precision: 0.9537037037037037 recall: 0.911504424778761 weighted: 0.9326040642412323
alpha = 0.54 precision: 0.9537037037037037 recall: 0.911504424778761 weighted: 0.9326040642412323
alpha = 0.55 precision: 0.9537037037037037 recall: 0.911504424778761 weighted: 0.9326040642412323
alpha = 0.56 precision: 0.9537037037037037 recall: 0.911504424778761 weighted: 0.9326040642412323
alpha = 0.5700000000000001 precision: 0.9537037037037037 recall: 0.911504424778761 weighted: 0.9326040642412323
alpha = 0.58 precision: 0.9537037037037037 recall: 0.911504424778761 weighted: 0.9326040642412323
alpha = 0.59 precision: 0.9537037037037037 recall: 0.911504424778761 weighted: 0.9326040642412323
alpha = 0.6 precision: 0.9528301886792453 recall: 0.8938053097345132 weighted: 0.9233177492068793
alpha = 0.61 precision: 0.9528301886792453 recall: 0.8938053097345132 weighted: 0.9233177492068793
alpha = 0.62 precision: 0.9528301886792453 recall: 0.8938053097345132 weighted: 0.9233177492068793
alpha = 0.63 precision: 0.9528301886792453 recall: 0.8938053097345132 weighted: 0.9233177492068793
alpha = 0.64 precision: 0.9509803921568627 recall: 0.8584070796460177 weighted: 0.9046937359014402
alpha = 0.65 precision: 0.9504950495049505 recall: 0.8495575221238938 weighted: 0.9000262858144221
alpha = 0.66 precision: 0.9494949494949495 recall: 0.831858407079646 weighted: 0.8906766782872977
alpha = 0.67 precision: 0.9489795918367347 recall: 0.8230088495575221 weighted: 0.8859942206971284
alpha = 0.68 precision: 0.9484536082474226 recall: 0.8141592920353983 weighted: 0.8813064501414105
alpha = 0.6900000000000001 precision: 0.9473684210526315 recall: 0.7964601769911505 weighted: 0.871914299021891
alpha = 0.7000000000000001 precision: 0.946236559139785 recall: 0.7787610619469026 weighted: 0.8624988105433438
alpha = 0.71 precision: 0.9550561797752809 recall: 0.7522123893805309 weighted: 0.8536342845779059
alpha = 0.72 precision: 0.9550561797752809 recall: 0.7522123893805309 weighted: 0.8536342845779059
alpha = 0.73 precision: 0.9545454545454546 recall: 0.7433628318584071 weighted: 0.8489541432019309
alpha = 0.74 precision: 0.9534883720930233 recall: 0.7256637168141593 weighted: 0.8395760444535914
alpha = 0.75 precision: 0.9642857142857143 recall: 0.7168141592920354 weighted: 0.8405499367888749
alpha = 0.76 precision: 0.9642857142857143 recall: 0.7168141592920354 weighted: 0.8405499367888749
alpha = 0.77 precision: 0.9642857142857143 recall: 0.7168141592920354 weighted: 0.8405499367888749
alpha = 0.78 precision: 0.9642857142857143 recall: 0.7168141592920354 weighted: 0.8405499367888749
alpha = 0.79 precision: 0.9642857142857143 recall: 0.7168141592920354 weighted: 0.8405499367888749
alpha = 0.8 precision: 0.9634146341463414 recall: 0.6991150442477876 weighted: 0.8312648391970645
alpha = 0.81 precision: 0.974025974025974 recall: 0.6637168141592921 weighted: 0.8188713940926331
alpha = 0.8200000000000001 precision: 0.9868421052631579 recall: 0.6637168141592921 weighted: 0.825279459711225
alpha = 0.8300000000000001 precision: 0.9866666666666667 recall: 0.6548672566371682 weighted: 0.8207669616519174
alpha = 0.84 precision: 0.9861111111111112 recall: 0.6283185840707964 weighted: 0.8072148475909537
alpha = 0.85 precision: 0.9859154929577465 recall: 0.6194690265486725 weighted: 0.8026922597532096
alpha = 0.86 precision: 0.9852941176470589 recall: 0.5929203539823009 weighted: 0.7891072358146799
alpha = 0.87 precision: 0.9846153846153847 recall: 0.5663716814159292 weighted: 0.7754935330156569
alpha = 0.88 precision: 0.9838709677419355 recall: 0.5398230088495575 weighted: 0.7618469882957465
alpha = 0.89 precision: 0.9836065573770492 recall: 0.5309734513274337 weighted: 0.7572900043522415
alpha = 0.9 precision: 0.9818181818181818 recall: 0.4778761061946903 weighted: 0.729847144006436
alpha = 0.91 precision: 0.9803921568627451 recall: 0.4424778761061947 weighted: 0.7114350164844698
alpha = 0.92 precision: 0.9787234042553191 recall: 0.40707964601769914 weighted: 0.6929015251365092
alpha = 0.93 precision: 1.0 recall: 0.3893805309734513 weighted: 0.6946902654867256
alpha = 0.9400000000000001 precision: 1.0 recall: 0.3274336283185841 weighted: 0.6637168141592921
alpha = 0.9500000000000001 precision: 1.0 recall: 0.26548672566371684 weighted: 0.6327433628318584
alpha = 0.96 precision: 1.0 recall: 0.22123893805309736 weighted: 0.6106194690265487
alpha = 0.97 precision: 1.0 recall: 0.1415929203539823 weighted: 0.5707964601769911
alpha = 0.98 precision: 1.0 recall: 0.05309734513274336 weighted: 0.5265486725663717
alpha = 0.99 precision: 1.0 recall: 0.017699115044247787 weighted: 0.5088495575221239
alpha = 1.0 precision: 1 recall: 0.0 weighted: 0.5
file name is: outputs/c__Bacilli_train.xlsx
split results is: ['outputs', 'c__Bacilli_train.xlsx']
