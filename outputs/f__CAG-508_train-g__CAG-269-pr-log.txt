alpha = 0.0 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.01 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.02 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.03 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.04 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.05 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.06 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.07 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.08 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.09 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.1 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.11 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.12 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.13 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.14 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.15 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.16 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.17 precision: 0.48253968253968255 recall: 0.48253968253968255 weighted: 0.48253968253968255
alpha = 0.18 precision: 0.4840764331210191 recall: 0.48253968253968255 weighted: 0.4833080578303508
alpha = 0.19 precision: 0.48562300319488816 recall: 0.48253968253968255 weighted: 0.4840813428672853
alpha = 0.2 precision: 0.49032258064516127 recall: 0.48253968253968255 weighted: 0.4864311315924219
alpha = 0.21 precision: 0.49032258064516127 recall: 0.48253968253968255 weighted: 0.4864311315924219
alpha = 0.22 precision: 0.49032258064516127 recall: 0.48253968253968255 weighted: 0.4864311315924219
alpha = 0.23 precision: 0.4919093851132686 recall: 0.48253968253968255 weighted: 0.48722453382647557
alpha = 0.24 precision: 0.4935064935064935 recall: 0.48253968253968255 weighted: 0.488023088023088
alpha = 0.25 precision: 0.4935064935064935 recall: 0.48253968253968255 weighted: 0.488023088023088
alpha = 0.26 precision: 0.49185667752442996 recall: 0.4793650793650794 weighted: 0.4856108784447547
alpha = 0.27 precision: 0.4934640522875817 recall: 0.4793650793650794 weighted: 0.4864145658263306
alpha = 0.28 precision: 0.4934640522875817 recall: 0.4793650793650794 weighted: 0.4864145658263306
alpha = 0.29 precision: 0.4934640522875817 recall: 0.4793650793650794 weighted: 0.4864145658263306
alpha = 0.3 precision: 0.49508196721311476 recall: 0.4793650793650794 weighted: 0.48722352328909707
alpha = 0.31 precision: 0.49508196721311476 recall: 0.4793650793650794 weighted: 0.48722352328909707
alpha = 0.32 precision: 0.4967105263157895 recall: 0.4793650793650794 weighted: 0.4880378028404344
alpha = 0.33 precision: 0.4967105263157895 recall: 0.4793650793650794 weighted: 0.4880378028404344
alpha = 0.34 precision: 0.4967105263157895 recall: 0.4793650793650794 weighted: 0.4880378028404344
alpha = 0.35000000000000003 precision: 0.4967105263157895 recall: 0.4793650793650794 weighted: 0.4880378028404344
alpha = 0.36 precision: 0.5 recall: 0.4793650793650794 weighted: 0.4896825396825397
alpha = 0.37 precision: 0.5 recall: 0.4793650793650794 weighted: 0.4896825396825397
alpha = 0.38 precision: 0.5 recall: 0.4793650793650794 weighted: 0.4896825396825397
alpha = 0.39 precision: 0.5050167224080268 recall: 0.4793650793650794 weighted: 0.49219090088655304
alpha = 0.4 precision: 0.5101351351351351 recall: 0.4793650793650794 weighted: 0.49475010725010726
alpha = 0.41000000000000003 precision: 0.5171232876712328 recall: 0.4793650793650794 weighted: 0.49824418351815614
alpha = 0.42 precision: 0.5172413793103449 recall: 0.47619047619047616 weighted: 0.4967159277504105
alpha = 0.43 precision: 0.5265017667844523 recall: 0.473015873015873 weighted: 0.49975881990016263
alpha = 0.44 precision: 0.5481481481481482 recall: 0.46984126984126984 weighted: 0.508994708994709
alpha = 0.45 precision: 0.5697211155378487 recall: 0.45396825396825397 weighted: 0.5118446847530513
alpha = 0.46 precision: 0.6020408163265306 recall: 0.3746031746031746 weighted: 0.4883219954648526
alpha = 0.47000000000000003 precision: 0.813953488372093 recall: 0.2222222222222222 weighted: 0.5180878552971576
alpha = 0.48 precision: 0.8163265306122449 recall: 0.12698412698412698 weighted: 0.47165532879818595
alpha = 0.49 precision: 0.918918918918919 recall: 0.10793650793650794 weighted: 0.5134277134277134
alpha = 0.5 precision: 0.9142857142857143 recall: 0.10158730158730159 weighted: 0.5079365079365079
alpha = 0.51 precision: 0.9142857142857143 recall: 0.10158730158730159 weighted: 0.5079365079365079
alpha = 0.52 precision: 0.9142857142857143 recall: 0.10158730158730159 weighted: 0.5079365079365079
alpha = 0.53 precision: 0.9117647058823529 recall: 0.09841269841269841 weighted: 0.5050887021475257
alpha = 0.54 precision: 0.90625 recall: 0.09206349206349207 weighted: 0.49915674603174603
alpha = 0.55 precision: 0.9032258064516129 recall: 0.08888888888888889 weighted: 0.4960573476702509
alpha = 0.56 precision: 0.9032258064516129 recall: 0.08888888888888889 weighted: 0.4960573476702509
alpha = 0.5700000000000001 precision: 0.9032258064516129 recall: 0.08888888888888889 weighted: 0.4960573476702509
alpha = 0.58 precision: 0.9032258064516129 recall: 0.08888888888888889 weighted: 0.4960573476702509
alpha = 0.59 precision: 0.9032258064516129 recall: 0.08888888888888889 weighted: 0.4960573476702509
alpha = 0.6 precision: 0.9 recall: 0.08571428571428572 weighted: 0.4928571428571429
alpha = 0.61 precision: 0.9 recall: 0.08571428571428572 weighted: 0.4928571428571429
alpha = 0.62 precision: 0.896551724137931 recall: 0.08253968253968254 weighted: 0.4895457033388068
alpha = 0.63 precision: 0.8928571428571429 recall: 0.07936507936507936 weighted: 0.48611111111111116
alpha = 0.64 precision: 0.8928571428571429 recall: 0.07936507936507936 weighted: 0.48611111111111116
alpha = 0.65 precision: 0.8928571428571429 recall: 0.07936507936507936 weighted: 0.48611111111111116
alpha = 0.66 precision: 0.8928571428571429 recall: 0.07936507936507936 weighted: 0.48611111111111116
alpha = 0.67 precision: 0.8928571428571429 recall: 0.07936507936507936 weighted: 0.48611111111111116
alpha = 0.68 precision: 0.8888888888888888 recall: 0.0761904761904762 weighted: 0.4825396825396825
alpha = 0.6900000000000001 precision: 0.8888888888888888 recall: 0.0761904761904762 weighted: 0.4825396825396825
alpha = 0.7000000000000001 precision: 0.8695652173913043 recall: 0.06349206349206349 weighted: 0.4665286404416839
alpha = 0.71 precision: 0.9090909090909091 recall: 0.06349206349206349 weighted: 0.4862914862914863
alpha = 0.72 precision: 0.9 recall: 0.05714285714285714 weighted: 0.4785714285714286
alpha = 0.73 precision: 0.9 recall: 0.05714285714285714 weighted: 0.4785714285714286
alpha = 0.74 precision: 0.8947368421052632 recall: 0.05396825396825397 weighted: 0.4743525480367586
alpha = 0.75 precision: 0.875 recall: 0.044444444444444446 weighted: 0.4597222222222222
alpha = 0.76 precision: 0.8571428571428571 recall: 0.0380952380952381 weighted: 0.4476190476190476
alpha = 0.77 precision: 0.8333333333333334 recall: 0.031746031746031744 weighted: 0.43253968253968256
alpha = 0.78 precision: 0.8333333333333334 recall: 0.031746031746031744 weighted: 0.43253968253968256
alpha = 0.79 precision: 0.7777777777777778 recall: 0.022222222222222223 weighted: 0.4
alpha = 0.8 precision: 0.6666666666666666 recall: 0.012698412698412698 weighted: 0.33968253968253964
alpha = 0.81 precision: 0.5 recall: 0.006349206349206349 weighted: 0.25317460317460316
alpha = 0.8200000000000001 precision: 0.0 recall: 0.0 weighted: 0.0
alpha = 0.8300000000000001 precision: 0.0 recall: 0.0 weighted: 0.0
alpha = 0.84 precision: 0.0 recall: 0.0 weighted: 0.0
alpha = 0.85 precision: 0.0 recall: 0.0 weighted: 0.0
alpha = 0.86 precision: 0.0 recall: 0.0 weighted: 0.0
alpha = 0.87 precision: 0.0 recall: 0.0 weighted: 0.0
alpha = 0.88 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.89 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.9 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.91 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.92 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.93 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.9400000000000001 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.9500000000000001 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.96 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.97 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.98 precision: 1 recall: 0.0 weighted: 0.5
alpha = 0.99 precision: 1 recall: 0.0 weighted: 0.5
alpha = 1.0 precision: 1 recall: 0.0 weighted: 0.5
file name is: outputs/f__CAG-508_train.xlsx
split results is: ['outputs', 'f__CAG-508_train.xlsx']
